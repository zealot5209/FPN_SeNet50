name: "SE-ResNet-50-Test"
# mean_value: 104, 117, 123
input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}

input: "im_info"
input_shape {
  dim: 1
  dim: 3
}

layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1/7x7_s2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "conv1/7x7_s2/bn"
  type: "BatchNorm"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/7x7_s2/bn/scale"
  type: "Scale"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/relu_7x7_s2"
  type: "ReLU"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_1_1x1_reduce"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2_1_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
}
layer {
  name: "conv2_1_3x3"
  type: "Convolution"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_3x3/relu"
  type: "ReLU"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
}
layer {
  name: "conv2_1_1x1_increase"
  type: "Convolution"
  bottom: "conv2_1_3x3"
  top: "conv2_1_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_global_pool"
  type: "Pooling"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_1_1x1_down"
  type: "Convolution"
  bottom: "conv2_1_global_pool"
  top: "conv2_1_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_1_1x1_down"
  top: "conv2_1_1x1_down"
}
layer {
  name: "conv2_1_1x1_up"
  type: "Convolution"
  bottom: "conv2_1_1x1_down"
  top: "conv2_1_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_prob"
  type: "Sigmoid"
  bottom: "conv2_1_1x1_up"
  top: "conv2_1_1x1_up"
}
layer {
  name: "conv2_1_1x1_proj"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2_1_1x1_proj"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Axpy"
  bottom: "conv2_1_1x1_up"
  bottom: "conv2_1_1x1_increase"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1"
}
layer {
  name: "conv2_1/relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
}
layer {
  name: "conv2_2_3x3"
  type: "Convolution"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_3x3/relu"
  type: "ReLU"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
}
layer {
  name: "conv2_2_1x1_increase"
  type: "Convolution"
  bottom: "conv2_2_3x3"
  top: "conv2_2_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_global_pool"
  type: "Pooling"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_2_1x1_down"
  type: "Convolution"
  bottom: "conv2_2_global_pool"
  top: "conv2_2_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_2_1x1_down"
  top: "conv2_2_1x1_down"
}
layer {
  name: "conv2_2_1x1_up"
  type: "Convolution"
  bottom: "conv2_2_1x1_down"
  top: "conv2_2_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_2_prob"
  type: "Sigmoid"
  bottom: "conv2_2_1x1_up"
  top: "conv2_2_1x1_up"
}
layer {
  name: "conv2_2"
  type: "Axpy"
  bottom: "conv2_2_1x1_up"
  bottom: "conv2_2_1x1_increase"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2/relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3_1x1_reduce"
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
}
layer {
  name: "conv2_3_3x3"
  type: "Convolution"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv2_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_3x3/relu"
  type: "ReLU"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
}
layer {
  name: "conv2_3_1x1_increase"
  type: "Convolution"
  bottom: "conv2_3_3x3"
  top: "conv2_3_1x1_increase"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_global_pool"
  type: "Pooling"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv2_3_1x1_down"
  type: "Convolution"
  bottom: "conv2_3_global_pool"
  top: "conv2_3_1x1_down"
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv2_3_1x1_down"
  top: "conv2_3_1x1_down"
}
layer {
  name: "conv2_3_1x1_up"
  type: "Convolution"
  bottom: "conv2_3_1x1_down"
  top: "conv2_3_1x1_up"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv2_3_prob"
  type: "Sigmoid"
  bottom: "conv2_3_1x1_up"
  top: "conv2_3_1x1_up"
}
layer {
  name: "conv2_3"
  type: "Axpy"
  bottom: "conv2_3_1x1_up"
  bottom: "conv2_3_1x1_increase"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3/relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv3_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv3_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
}
layer {
  name: "conv3_1_3x3"
  type: "Convolution"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_3x3/relu"
  type: "ReLU"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
}
layer {
  name: "conv3_1_1x1_increase"
  type: "Convolution"
  bottom: "conv3_1_3x3"
  top: "conv3_1_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_global_pool"
  type: "Pooling"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_1_1x1_down"
  type: "Convolution"
  bottom: "conv3_1_global_pool"
  top: "conv3_1_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_1_1x1_down"
  top: "conv3_1_1x1_down"
}
layer {
  name: "conv3_1_1x1_up"
  type: "Convolution"
  bottom: "conv3_1_1x1_down"
  top: "conv3_1_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_1_prob"
  type: "Sigmoid"
  bottom: "conv3_1_1x1_up"
  top: "conv3_1_1x1_up"
}
layer {
  name: "conv3_1_1x1_proj"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_proj"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv3_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Axpy"
  bottom: "conv3_1_1x1_up"
  bottom: "conv3_1_1x1_increase"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1"
}
layer {
  name: "conv3_1/relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
}
layer {
  name: "conv3_2_3x3"
  type: "Convolution"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_3x3/relu"
  type: "ReLU"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
}
layer {
  name: "conv3_2_1x1_increase"
  type: "Convolution"
  bottom: "conv3_2_3x3"
  top: "conv3_2_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_global_pool"
  type: "Pooling"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_2_1x1_down"
  type: "Convolution"
  bottom: "conv3_2_global_pool"
  top: "conv3_2_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_2_1x1_down"
  top: "conv3_2_1x1_down"
}
layer {
  name: "conv3_2_1x1_up"
  type: "Convolution"
  bottom: "conv3_2_1x1_down"
  top: "conv3_2_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_2_prob"
  type: "Sigmoid"
  bottom: "conv3_2_1x1_up"
  top: "conv3_2_1x1_up"
}
layer {
  name: "conv3_2"
  type: "Axpy"
  bottom: "conv3_2_1x1_up"
  bottom: "conv3_2_1x1_increase"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2/relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
}
layer {
  name: "conv3_3_3x3"
  type: "Convolution"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_3x3/relu"
  type: "ReLU"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
}
layer {
  name: "conv3_3_1x1_increase"
  type: "Convolution"
  bottom: "conv3_3_3x3"
  top: "conv3_3_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_global_pool"
  type: "Pooling"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_3_1x1_down"
  type: "Convolution"
  bottom: "conv3_3_global_pool"
  top: "conv3_3_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_3_1x1_down"
  top: "conv3_3_1x1_down"
}
layer {
  name: "conv3_3_1x1_up"
  type: "Convolution"
  bottom: "conv3_3_1x1_down"
  top: "conv3_3_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_3_prob"
  type: "Sigmoid"
  bottom: "conv3_3_1x1_up"
  top: "conv3_3_1x1_up"
}
layer {
  name: "conv3_3"
  type: "Axpy"
  bottom: "conv3_3_1x1_up"
  bottom: "conv3_3_1x1_increase"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3/relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4_1x1_reduce"
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
}
layer {
  name: "conv3_4_3x3"
  type: "Convolution"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_3x3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv3_4_3x3/bn"
  type: "BatchNorm"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_3x3/bn/scale"
  type: "Scale"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_3x3/relu"
  type: "ReLU"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
}
layer {
  name: "conv3_4_1x1_increase"
  type: "Convolution"
  bottom: "conv3_4_3x3"
  top: "conv3_4_1x1_increase"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_global_pool"
  type: "Pooling"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv3_4_1x1_down"
  type: "Convolution"
  bottom: "conv3_4_global_pool"
  top: "conv3_4_1x1_down"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_1x1_down/relu"
  type: "ReLU"
  bottom: "conv3_4_1x1_down"
  top: "conv3_4_1x1_down"
}
layer {
  name: "conv3_4_1x1_up"
  type: "Convolution"
  bottom: "conv3_4_1x1_down"
  top: "conv3_4_1x1_up"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv3_4_prob"
  type: "Sigmoid"
  bottom: "conv3_4_1x1_up"
  top: "conv3_4_1x1_up"
}
layer {
  name: "conv3_4"
  type: "Axpy"
  bottom: "conv3_4_1x1_up"
  bottom: "conv3_4_1x1_increase"
  bottom: "conv3_3"
  top: "conv3_4"
}
layer {
  name: "conv3_4/relu"
  type: "ReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv4_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv4_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
}
layer {
  name: "conv4_1_3x3"
  type: "Convolution"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_3x3/relu"
  type: "ReLU"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
}
layer {
  name: "conv4_1_1x1_increase"
  type: "Convolution"
  bottom: "conv4_1_3x3"
  top: "conv4_1_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_global_pool"
  type: "Pooling"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_1_1x1_down"
  type: "Convolution"
  bottom: "conv4_1_global_pool"
  top: "conv4_1_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_1_1x1_down"
  top: "conv4_1_1x1_down"
}
layer {
  name: "conv4_1_1x1_up"
  type: "Convolution"
  bottom: "conv4_1_1x1_down"
  top: "conv4_1_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_1_prob"
  type: "Sigmoid"
  bottom: "conv4_1_1x1_up"
  top: "conv4_1_1x1_up"
}
layer {
  name: "conv4_1_1x1_proj"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_proj"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv4_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Axpy"
  bottom: "conv4_1_1x1_up"
  bottom: "conv4_1_1x1_increase"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1"
}
layer {
  name: "conv4_1/relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
}
layer {
  name: "conv4_2_3x3"
  type: "Convolution"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_3x3/relu"
  type: "ReLU"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
}
layer {
  name: "conv4_2_1x1_increase"
  type: "Convolution"
  bottom: "conv4_2_3x3"
  top: "conv4_2_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_global_pool"
  type: "Pooling"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_2_1x1_down"
  type: "Convolution"
  bottom: "conv4_2_global_pool"
  top: "conv4_2_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_2_1x1_down"
  top: "conv4_2_1x1_down"
}
layer {
  name: "conv4_2_1x1_up"
  type: "Convolution"
  bottom: "conv4_2_1x1_down"
  top: "conv4_2_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_2_prob"
  type: "Sigmoid"
  bottom: "conv4_2_1x1_up"
  top: "conv4_2_1x1_up"
}
layer {
  name: "conv4_2"
  type: "Axpy"
  bottom: "conv4_2_1x1_up"
  bottom: "conv4_2_1x1_increase"
  bottom: "conv4_1"
  top: "conv4_2"
}
layer {
  name: "conv4_2/relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
}
layer {
  name: "conv4_3_3x3"
  type: "Convolution"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_3x3/relu"
  type: "ReLU"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
}
layer {
  name: "conv4_3_1x1_increase"
  type: "Convolution"
  bottom: "conv4_3_3x3"
  top: "conv4_3_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_global_pool"
  type: "Pooling"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_3_1x1_down"
  type: "Convolution"
  bottom: "conv4_3_global_pool"
  top: "conv4_3_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_3_1x1_down"
  top: "conv4_3_1x1_down"
}
layer {
  name: "conv4_3_1x1_up"
  type: "Convolution"
  bottom: "conv4_3_1x1_down"
  top: "conv4_3_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_3_prob"
  type: "Sigmoid"
  bottom: "conv4_3_1x1_up"
  top: "conv4_3_1x1_up"
}
layer {
  name: "conv4_3"
  type: "Axpy"
  bottom: "conv4_3_1x1_up"
  bottom: "conv4_3_1x1_increase"
  bottom: "conv4_2"
  top: "conv4_3"
}
layer {
  name: "conv4_3/relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
}
layer {
  name: "conv4_4_3x3"
  type: "Convolution"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_4_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_3x3/relu"
  type: "ReLU"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
}
layer {
  name: "conv4_4_1x1_increase"
  type: "Convolution"
  bottom: "conv4_4_3x3"
  top: "conv4_4_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_global_pool"
  type: "Pooling"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_4_1x1_down"
  type: "Convolution"
  bottom: "conv4_4_global_pool"
  top: "conv4_4_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_4_1x1_down"
  top: "conv4_4_1x1_down"
}
layer {
  name: "conv4_4_1x1_up"
  type: "Convolution"
  bottom: "conv4_4_1x1_down"
  top: "conv4_4_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_4_prob"
  type: "Sigmoid"
  bottom: "conv4_4_1x1_up"
  top: "conv4_4_1x1_up"
}
layer {
  name: "conv4_4"
  type: "Axpy"
  bottom: "conv4_4_1x1_up"
  bottom: "conv4_4_1x1_increase"
  bottom: "conv4_3"
  top: "conv4_4"
}
layer {
  name: "conv4_4/relu"
  type: "ReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "conv4_5_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_4"
  top: "conv4_5_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
}
layer {
  name: "conv4_5_3x3"
  type: "Convolution"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_5_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_3x3/relu"
  type: "ReLU"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
}
layer {
  name: "conv4_5_1x1_increase"
  type: "Convolution"
  bottom: "conv4_5_3x3"
  top: "conv4_5_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_5_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_5_global_pool"
  type: "Pooling"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_5_1x1_down"
  type: "Convolution"
  bottom: "conv4_5_global_pool"
  top: "conv4_5_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_5_1x1_down"
  top: "conv4_5_1x1_down"
}
layer {
  name: "conv4_5_1x1_up"
  type: "Convolution"
  bottom: "conv4_5_1x1_down"
  top: "conv4_5_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_5_prob"
  type: "Sigmoid"
  bottom: "conv4_5_1x1_up"
  top: "conv4_5_1x1_up"
}
layer {
  name: "conv4_5"
  type: "Axpy"
  bottom: "conv4_5_1x1_up"
  bottom: "conv4_5_1x1_increase"
  bottom: "conv4_4"
  top: "conv4_5"
}
layer {
  name: "conv4_5/relu"
  type: "ReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6_1x1_reduce"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
}
layer {
  name: "conv4_6_3x3"
  type: "Convolution"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_3x3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv4_6_3x3/bn"
  type: "BatchNorm"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_3x3/bn/scale"
  type: "Scale"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_3x3/relu"
  type: "ReLU"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
}
layer {
  name: "conv4_6_1x1_increase"
  type: "Convolution"
  bottom: "conv4_6_3x3"
  top: "conv4_6_1x1_increase"
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_6_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_6_global_pool"
  type: "Pooling"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv4_6_1x1_down"
  type: "Convolution"
  bottom: "conv4_6_global_pool"
  top: "conv4_6_1x1_down"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_1x1_down/relu"
  type: "ReLU"
  bottom: "conv4_6_1x1_down"
  top: "conv4_6_1x1_down"
}
layer {
  name: "conv4_6_1x1_up"
  type: "Convolution"
  bottom: "conv4_6_1x1_down"
  top: "conv4_6_1x1_up"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv4_6_prob"
  type: "Sigmoid"
  bottom: "conv4_6_1x1_up"
  top: "conv4_6_1x1_up"
}
layer {
  name: "conv4_6"
  type: "Axpy"
  bottom: "conv4_6_1x1_up"
  bottom: "conv4_6_1x1_increase"
  bottom: "conv4_5"
  top: "conv4_6"
}
layer {
  name: "conv4_6/relu"
  type: "ReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "conv5_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv5_1_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
}
layer {
  name: "conv5_1_3x3"
  type: "Convolution"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_1_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_3x3/relu"
  type: "ReLU"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
}
layer {
  name: "conv5_1_1x1_increase"
  type: "Convolution"
  bottom: "conv5_1_3x3"
  top: "conv5_1_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_global_pool"
  type: "Pooling"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_1_1x1_down"
  type: "Convolution"
  bottom: "conv5_1_global_pool"
  top: "conv5_1_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_1_1x1_down"
  top: "conv5_1_1x1_down"
}
layer {
  name: "conv5_1_1x1_up"
  type: "Convolution"
  bottom: "conv5_1_1x1_down"
  top: "conv5_1_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_1_prob"
  type: "Sigmoid"
  bottom: "conv5_1_1x1_up"
  top: "conv5_1_1x1_up"
}
layer {
  name: "conv5_1_1x1_proj"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_proj"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "conv5_1_1x1_proj/bn"
  type: "BatchNorm"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1_1x1_proj"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1_1x1_proj/bn/scale"
  type: "Scale"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1_1x1_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1"
  type: "Axpy"
  bottom: "conv5_1_1x1_up"
  bottom: "conv5_1_1x1_increase"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1"
}
layer {
  name: "conv5_1/relu"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
}
layer {
  name: "conv5_2_3x3"
  type: "Convolution"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_2_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_3x3/relu"
  type: "ReLU"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
}
layer {
  name: "conv5_2_1x1_increase"
  type: "Convolution"
  bottom: "conv5_2_3x3"
  top: "conv5_2_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_global_pool"
  type: "Pooling"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_2_1x1_down"
  type: "Convolution"
  bottom: "conv5_2_global_pool"
  top: "conv5_2_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_2_1x1_down"
  top: "conv5_2_1x1_down"
}
layer {
  name: "conv5_2_1x1_up"
  type: "Convolution"
  bottom: "conv5_2_1x1_down"
  top: "conv5_2_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_2_prob"
  type: "Sigmoid"
  bottom: "conv5_2_1x1_up"
  top: "conv5_2_1x1_up"
}
layer {
  name: "conv5_2"
  type: "Axpy"
  bottom: "conv5_2_1x1_up"
  bottom: "conv5_2_1x1_increase"
  bottom: "conv5_1"
  top: "conv5_2"
}
layer {
  name: "conv5_2/relu"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3_1x1_reduce"
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_1x1_reduce/bn/scale"
  type: "Scale"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
}
layer {
  name: "conv5_3_3x3"
  type: "Convolution"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_3x3"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "conv5_3_3x3/bn"
  type: "BatchNorm"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_3x3/bn/scale"
  type: "Scale"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_3x3/relu"
  type: "ReLU"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
}
layer {
  name: "conv5_3_1x1_increase"
  type: "Convolution"
  bottom: "conv5_3_3x3"
  top: "conv5_3_1x1_increase"
  convolution_param {
    num_output: 2048
    bias_term: false
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_increase/bn"
  type: "BatchNorm"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_1x1_increase"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3_1x1_increase/bn/scale"
  type: "Scale"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_1x1_increase"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3_global_pool"
  type: "Pooling"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_global_pool"
  pooling_param {
    pool: AVE
    engine: CAFFE
    global_pooling: true
  }
}
layer {
  name: "conv5_3_1x1_down"
  type: "Convolution"
  bottom: "conv5_3_global_pool"
  top: "conv5_3_1x1_down"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_1x1_down/relu"
  type: "ReLU"
  bottom: "conv5_3_1x1_down"
  top: "conv5_3_1x1_down"
}
layer {
  name: "conv5_3_1x1_up"
  type: "Convolution"
  bottom: "conv5_3_1x1_down"
  top: "conv5_3_1x1_up"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv5_3_prob"
  type: "Sigmoid"
  bottom: "conv5_3_1x1_up"
  top: "conv5_3_1x1_up"
}
layer {
  name: "conv5_3"
  type: "Axpy"
  bottom: "conv5_3_1x1_up"
  bottom: "conv5_3_1x1_increase"
  bottom: "conv5_2"
  top: "conv5_3"
}
layer {
  name: "conv5_3/relu"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}


##====FPN====##
#layer {
#	bottom: "res5b"
#	bottom: "res5c_branch2c"
#	top: "res5c"
#	name: "res5c"
#	type: "Eltwise"
#}

#layer {
#	bottom: "res5c"
#	top: "res5c"
#	name: "res5c_relu"
#	type: "ReLU"
#}

layer {
	bottom: "conv5_3"
	top: "res6"
	name: "pool_res6"
	type: "Pooling"
	pooling_param {
		kernel_size: 3
		stride: 2
		pool: MAX
	}
}
####lateral

layer {
	bottom: "res6"
	top: "p6"
	name: "p6"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
        
	}
}

layer {
	bottom: "conv5_3"
	top: "p5"
	name: "p5"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
        
	}
}

layer {
    name: "upP5"
	type: "Deconvolution"
    bottom: "p5" 
	top: "upP5"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}

layer {
	bottom: "conv4_6"
	top: "c4"
	name: "newC4"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}

layer {
    name: "p4"
    type: "Eltwise"
    bottom: "c4"
    bottom: "upP5"
    top: "p4"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "p4"
	top: "p4_lateral"
	name: "p4_lateral"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "upP4"
	type: "Deconvolution"
    bottom: "p4_lateral" 
	top: "upP4"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}


layer {
	bottom: "conv3_4"
	top: "c3"
	name: "newC3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "p3"
    type: "Eltwise"
    bottom: "c3"
    bottom: "upP4"
    top: "p3"
    eltwise_param {
        operation: SUM
    }
}


layer {
	bottom: "p3"
	top: "p3_lateral"
	name: "p3_lateral"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}

layer {
	bottom: "conv2_3"
	top: "c2"
	name: "newC2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0.0 }
        
	}
}
layer {
    name: "upP2"
	type: "Deconvolution"
    bottom: "p3_lateral" 
	top: "upP2"
    convolution_param {
    kernel_h : 4
    kernel_w : 4
    stride_h: 2
    stride_w: 2
    pad_h: 1
    pad_w: 1
    num_output: 256
    group: 256
    bias_term: false
     weight_filler {
      type: "bilinear"
    }
  }
  param { lr_mult: 0 decay_mult: 0 } 
}
layer {
    name: "p2"
    type: "Eltwise"
    bottom: "c2"
    bottom: "upP2"
    top: "p2"
    eltwise_param {
        operation: SUM
    }
}




####

#========= RPN/p2 ============

layer {
  name: "rpn_conv/3x3/p2"
  type: "Convolution"
  bottom: "p2"
  top: "rpn/output/p2"
  param { lr_mult: 1.0
  		  name: "rpn_conv_3x3_w"
          }
  param { lr_mult: 2.0
  		  name: "rpn_conv_3x3_b"
          }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p2"
  type: "ReLU"
  bottom: "rpn/output/p2"
  top: "rpn/output/p2"
}

layer {
  name: "rpn_cls_score/p2"
  type: "Convolution"
  bottom: "rpn/output/p2"
  top: "rpn_cls_score/p2"
  param { lr_mult: 1.0
  		name: "rpn_cls_score_w" }
  param { lr_mult: 2.0
 		name: "rpn_cls_score_b"
        }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p2"
  type: "Convolution"
  bottom: "rpn/output/p2"
  top: "rpn_bbox_pred/p2"
  param { lr_mult: 1.0
  		name: "rpn_bbox_pred_w"
        }
  param { lr_mult: 2.0
  name: "rpn_bbox_pred_b"
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p2"
   top: "rpn_cls_score_reshape_/p2"
   name: "rpn_cls_score_reshape_/p2"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p2"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p2"
  top: "fpn_out/p2"
}

layer {
   bottom: "fpn_out/p2"
   top: "fpn_out_reshape/p2"
   name: "fpn_out_reshape/p2"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}


#========= RPN/p3 ============

layer {
  name: "rpn_conv/3x3/p3"
  type: "Convolution"
  bottom: "p3"
  top: "rpn/output/p3"
  param { lr_mult: 1.0
        name: "rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0 
   name: "rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p3"
  type: "ReLU"
  bottom: "rpn/output/p3"
  top: "rpn/output/p3"
}

layer {
  name: "rpn_cls_score/p3"
  type: "Convolution"
  bottom: "rpn/output/p3"
  top: "rpn_cls_score/p3"
  param { lr_mult: 1.0 
  name: "rpn_cls_score_w"
  }
  param { lr_mult: 2.0
    name: "rpn_cls_score_b"
    }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p3"
  type: "Convolution"
  bottom: "rpn/output/p3"
  top: "rpn_bbox_pred/p3"
  param { lr_mult: 1.0
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
   name:"rpn_bbox_pred_b" 
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p3"
   top: "rpn_cls_score_reshape_/p3"
   name: "rpn_cls_score_reshape_/p3"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p3"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p3"
  top: "fpn_out/p3"
}

layer {
   bottom: "fpn_out/p3"
   top: "fpn_out_reshape/p3"
   name: "fpn_out_reshape/p3"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}



#========= RPN/p4 ============

layer {
  name: "rpn_conv/3x3/p4"
  type: "Convolution"
  bottom: "p4"
  top: "rpn/output/p4"
  param { lr_mult: 1.0
  name: "rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0 
    name: "rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p4"
  type: "ReLU"
  bottom: "rpn/output/p4"
  top: "rpn/output/p4"
}

layer {
  name: "rpn_cls_score/p4"
  type: "Convolution"
  bottom: "rpn/output/p4"
  top: "rpn_cls_score/p4"
  param { lr_mult: 1.0 
  name:"rpn_cls_score_w"
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
    }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p4"
  type: "Convolution"
  bottom: "rpn/output/p4"
  top: "rpn_bbox_pred/p4"
  param { lr_mult: 1.0
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
  }
  convolution_param {
    num_output: 24   # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.001 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p4"
   top: "rpn_cls_score_reshape_/p4"
   name: "rpn_cls_score_reshape_/p4"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p4"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p4"
  top: "fpn_out/p4"
}

layer {
   bottom: "fpn_out/p4"
   top: "fpn_out_reshape/p4"
   name: "fpn_out_reshape/p4"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}




#========= RPN/p5 ============

layer {
  name: "rpn_conv/3x3/p5"
  type: "Convolution"
  bottom: "p5"
  top: "rpn/output/p5"
  param { lr_mult: 1.0
  name:"rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0
    name:"rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p5"
  type: "ReLU"
  bottom: "rpn/output/p5"
  top: "rpn/output/p5"
}

layer {
  name: "rpn_cls_score/p5"
  type: "Convolution"
  bottom: "rpn/output/p5"
  top: "rpn_cls_score/p5"
  param { lr_mult: 1.0
  name:"rpn_cls_score_w"
  
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
  }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p5"
  type: "Convolution"
  bottom: "rpn/output/p5"
  top: "rpn_bbox_pred/p5"
  param { lr_mult: 1.0 
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
    }
  convolution_param {
    num_output: 24  # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

######

layer {
   bottom: "rpn_cls_score/p5"
   top: "rpn_cls_score_reshape_/p5"
   name: "rpn_cls_score_reshape_/p5"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p5"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p5"
  top: "fpn_out/p5"
}

layer {
   bottom: "fpn_out/p5"
   top: "fpn_out_reshape/p5"
   name: "fpn_out_reshape/p5"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}

#========= RPN/p6 ============

layer {
  name: "rpn_conv/3x3/p6"
  type: "Convolution"
  bottom: "p6"
  top: "rpn/output/p6"
  param { lr_mult: 1.0
  name:"rpn_conv_3x3_w"
  }
  param { lr_mult: 2.0
    name:"rpn_conv_3x3_b"
  }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3/p6"
  type: "ReLU"
  bottom: "rpn/output/p6"
  top: "rpn/output/p6"
}

layer {
  name: "rpn_cls_score/p6"
  type: "Convolution"
  bottom: "rpn/output/p6"
  top: "rpn_cls_score/p6"
  param { lr_mult: 1.0
  name:"rpn_cls_score_w"
  
  }
  param { lr_mult: 2.0
  name:"rpn_cls_score_b"
  }
  convolution_param {
    num_output: 12   # 2(bg/fg) * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}

layer {
  name: "rpn_bbox_pred/p6"
  type: "Convolution"
  bottom: "rpn/output/p6"
  top: "rpn_bbox_pred/p6"
  param { lr_mult: 1.0 
  name:"rpn_bbox_pred_w"
  }
  param { lr_mult: 2.0
    name:"rpn_bbox_pred_b"
    }
  convolution_param {
    num_output: 24  # 4 * 9(anchors)
    kernel_size: 1 pad: 0 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}


######

layer {
   bottom: "rpn_cls_score/p6"
   top: "rpn_cls_score_reshape_/p6"
   name: "rpn_cls_score_reshape_/p6"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 2 dim: -1 dim:0} }
}






#####CLS out


layer {
  name: "fpn_out/p6"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape_/p6"
  top: "fpn_out/p6"
}

layer {
   bottom: "fpn_out/p6"
   top: "fpn_out_reshape/p6"
   name: "fpn_out_reshape/p6"
   type: "Reshape"
   reshape_param { shape {dim: 0 dim: 12 dim: -1 dim: 0  } }
}






#========= RoI Proposal ============



 

layer {
  name: 'proposal'
  type: 'Python'
    bottom: 'im_info'
    bottom: 'rpn_bbox_pred/p2'
    bottom: 'rpn_bbox_pred/p3'
	bottom: 'rpn_bbox_pred/p4'
	bottom: 'rpn_bbox_pred/p5'
	bottom: 'rpn_bbox_pred/p6'
 	bottom: 'fpn_out_reshape/p2'
	bottom: 'fpn_out_reshape/p3'
	bottom: 'fpn_out_reshape/p4'
	bottom: 'fpn_out_reshape/p5'
	bottom: 'fpn_out_reshape/p6'
  top: 'rpn_rois'
  python_param {
    module: 'rpn.proposal_layer'
    layer: 'ProposalLayer'
    param_str: "'feat_stride': 4,8,16,32,64"

  }
}



#================rois process======================


layer {
  name: 'as_rois'
  type: 'Python'
  bottom: 'rpn_rois'
  top: 'rois'
  top: 'rois/h2'
  top: 'rois/h3'
  top: 'rois/h4'
  top: 'rois/h5'
  python_param {
    module: 'rpn.as_rois'
    layer: 'As_roisLayer'

  }
}


#========= RCNN ============

######POOLING=======
layer {
  name: "roi_pool/h2"
  type: "ROIPooling"
  bottom: "p2"
  bottom: "rois/h2"
  top: "roi_pool/h2"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.25 # 1/4
  }
}


layer {
  name: "roi_pool/h3"
  type: "ROIPooling"
  bottom: "p3"
  bottom: "rois/h3"
  top: "roi_pool/h3"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.125 # 1/8
  }
}
layer {
  name: "roi_pool/h4"
  type: "ROIPooling"
  bottom: "p4"
  bottom: "rois/h4"
  top: "roi_pool/h4"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.0625 # 1/16
  }
}

layer {
  name: "roi_pool/h5"
  type: "ROIPooling"
  bottom: "p5"
  bottom: "rois/h5"
  top: "roi_pool/h5"
  roi_pooling_param {
    pooled_w: 7
    pooled_h: 7
    spatial_scale: 0.03125 # 1/32
  }
}




#h2
layer {
  name: "rcnn_fc6/h2"
  type: "InnerProduct"
  bottom: "roi_pool/h2"
  top: "rcnn_fc6/h2"
  param {
    lr_mult: 1
    name: "rcnn_fc6_w"
  }
  param {
    lr_mult: 2
    name: "rcnn_fc6_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6/h2"
  type: "ReLU"
  bottom: "rcnn_fc6/h2"
  top: "rcnn_fc6/h2"
}
layer {
  name: "drop6/h2"
  type: "Dropout"
  bottom: "rcnn_fc6/h2"
  top: "rcnn_fc6/h2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7/h2"
  type: "InnerProduct"
  bottom: "rcnn_fc6/h2"
  top: "fc7/h2"
  param {
    lr_mult: 1
    name:"fc7_w"
  }
  param {
    lr_mult: 2
    name: "fc7_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {  
    type: "xavier"  
    }  
    bias_filler {  
      type: "constant"  
    } 
  }
}
layer {
  name: "relu7/h2"
  type: "ReLU"
  bottom: "fc7/h2"
  top: "fc7/h2"
}
layer {
  name: "drop7/h2"
  type: "Dropout"
  bottom: "fc7/h2"
  top: "fc7/h2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score/h2"
  type: "InnerProduct"
  bottom: "fc7/h2"
  top: "cls_score/h2"
  param {
    lr_mult: 1
    name:"cls_score_w"
  }
  param {
    lr_mult: 2
    name:"cls_score_b"
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred/h2"
  type: "InnerProduct"
  bottom: "fc7/h2"
  top: "bbox_pred/h2"
  param {
    lr_mult: 1
    name:"bbox_pred_w"
  }
  param {
    lr_mult: 2
    name:"bbox_pred_b"
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}




#h3
layer {
  name: "rcnn_fc6/h3"
  type: "InnerProduct"
  bottom: "roi_pool/h3"
  top: "rcnn_fc6/h3"
  param {
    lr_mult: 1
    name: "rcnn_fc6_w"
  }
  param {
    lr_mult: 2
    name: "rcnn_fc6_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6/h3"
  type: "ReLU"
  bottom: "rcnn_fc6/h3"
  top: "rcnn_fc6/h3"
}
layer {
  name: "drop6/h3"
  type: "Dropout"
  bottom: "rcnn_fc6/h3"
  top: "rcnn_fc6/h3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7/h3"
  type: "InnerProduct"
  bottom: "rcnn_fc6/h3"
  top: "fc7/h3"
  param {
    lr_mult: 1
    name:"fc7_w"
  }
  param {
    lr_mult: 2
    name: "fc7_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {  
    type: "xavier"  
    }  
    bias_filler {  
      type: "constant"  
    } 
  }
}
layer {
  name: "relu7/h3"
  type: "ReLU"
  bottom: "fc7/h3"
  top: "fc7/h3"
}
layer {
  name: "drop7/h3"
  type: "Dropout"
  bottom: "fc7/h3"
  top: "fc7/h3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score/h3"
  type: "InnerProduct"
  bottom: "fc7/h3"
  top: "cls_score/h3"
  param {
    lr_mult: 1
    name:"cls_score_w"
  }
  param {
    lr_mult: 2
    name:"cls_score_b"
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred/h3"
  type: "InnerProduct"
  bottom: "fc7/h3"
  top: "bbox_pred/h3"
  param {
    lr_mult: 1
    name:"bbox_pred_w"
  }
  param {
    lr_mult: 2
    name:"bbox_pred_b"
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}





#h4
layer {
  name: "rcnn_fc6/h4"
  type: "InnerProduct"
  bottom: "roi_pool/h4"
  top: "rcnn_fc6/h4"
  param {
    lr_mult: 1
    name: "rcnn_fc6_w"
  }
  param {
    lr_mult: 2
    name: "rcnn_fc6_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6/h4"
  type: "ReLU"
  bottom: "rcnn_fc6/h4"
  top: "rcnn_fc6/h4"
}
layer {
  name: "drop6/h4"
  type: "Dropout"
  bottom: "rcnn_fc6/h4"
  top: "rcnn_fc6/h4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7/h4"
  type: "InnerProduct"
  bottom: "rcnn_fc6/h4"
  top: "fc7/h4"
  param {
    lr_mult: 1
    name:"fc7_w"
  }
  param {
    lr_mult: 2
    name: "fc7_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {  
    type: "xavier"  
    }  
    bias_filler {  
      type: "constant"  
    } 
  }
}
layer {
  name: "relu7/h4"
  type: "ReLU"
  bottom: "fc7/h4"
  top: "fc7/h4"
}
layer {
  name: "drop7/h4"
  type: "Dropout"
  bottom: "fc7/h4"
  top: "fc7/h4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score/h4"
  type: "InnerProduct"
  bottom: "fc7/h4"
  top: "cls_score/h4"
  param {
    lr_mult: 1
    name:"cls_score_w"
  }
  param {
    lr_mult: 2
    name:"cls_score_b"
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred/h4"
  type: "InnerProduct"
  bottom: "fc7/h4"
  top: "bbox_pred/h4"
  param {
    lr_mult: 1
    name:"bbox_pred_w"
  }
  param {
    lr_mult: 2
    name:"bbox_pred_b"
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#h5
layer {
  name: "rcnn_fc6/h5"
  type: "InnerProduct"
  bottom: "roi_pool/h5"
  top: "rcnn_fc6/h5"
  param {
    lr_mult: 1
    name: "rcnn_fc6_w"
  }
  param {
    lr_mult: 2
    name: "rcnn_fc6_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6/h5"
  type: "ReLU"
  bottom: "rcnn_fc6/h5"
  top: "rcnn_fc6/h5"
}
layer {
  name: "drop6/h5"
  type: "Dropout"
  bottom: "rcnn_fc6/h5"
  top: "rcnn_fc6/h5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7/h5"
  type: "InnerProduct"
  bottom: "rcnn_fc6/h5"
  top: "fc7/h5"
  param {
    lr_mult: 1
    name:"fc7_w"
  }
  param {
    lr_mult: 2
    name: "fc7_b"
  }
  inner_product_param {
    num_output: 4096
    weight_filler {  
    type: "xavier"  
    }  
    bias_filler {  
      type: "constant"  
    } 
  }
}
layer {
  name: "relu7/h5"
  type: "ReLU"
  bottom: "fc7/h5"
  top: "fc7/h5"
}
layer {
  name: "drop7/h5"
  type: "Dropout"
  bottom: "fc7/h5"
  top: "fc7/h5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score/h5"
  type: "InnerProduct"
  bottom: "fc7/h5"
  top: "cls_score/h5"
  param {
    lr_mult: 1
    name:"cls_score_w"
  }
  param {
    lr_mult: 2
    name:"cls_score_b"
  }
  inner_product_param {
    num_output: 21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred/h5"
  type: "InnerProduct"
  bottom: "fc7/h5"
  top: "bbox_pred/h5"
  param {
    lr_mult: 1
    name:"bbox_pred_w"
  }
  param {
    lr_mult: 2
    name:"bbox_pred_b"
  }
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}



layer {
  name: "cls_score_concat"
  type: "Concat"
  bottom: "cls_score/h2"
  bottom: "cls_score/h3"
  bottom: "cls_score/h4"
  bottom: "cls_score/h5"
  top: "cls_score"
  concat_param {
    axis: 0
  }
}

layer {
  name: "bbox_pred_concat"
  type: "Concat"
  bottom: "bbox_pred/h2"
  bottom: "bbox_pred/h3"
  bottom: "bbox_pred/h4"
  bottom: "bbox_pred/h5"
  top: "bbox_pred"
  concat_param {
    axis: 0
  }
}

layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
